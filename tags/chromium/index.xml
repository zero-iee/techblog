<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>chromium on ZERO GmbH Tech Blog</title><link>https://blog.zero-iee.com/tags/chromium/</link><description>ZERO GmbH Tech Blog (chromium)</description><generator>Hugo -- gohugo.io</generator><language>de</language><lastBuildDate>Wed, 08 Feb 2023 10:36:44 +0100</lastBuildDate><atom:link href="https://blog.zero-iee.com/tags/chromium/index.xml" rel="self" type="application/rss+xml"/><item><title>Qt Webengine (Chromium): Too Many Open Files</title><link>https://blog.zero-iee.com/posts/qt-webengine-chromium-too-many-open-files/</link><pubDate>Wed, 08 Feb 2023 10:36:44 +0100</pubDate><guid>https://blog.zero-iee.com/posts/qt-webengine-chromium-too-many-open-files/</guid><description>&lt;p>Wie bereits in früheren Blogposts erwähnt, nutzen wir innerhalb einer Qt Quick Anwendung die Chromium-basierte Qt WebEngine, um Webinhalte darstellen zu lassen. Im Laufe der Entwicklung haben wir allerdings einen unerfreulichen Bug entdeckt, der unsere Anwendung nach einiger Zeit im laufenden Betrieb abstürzen lässt. Zunächst friert das Web-Fenster ein - etwas später folgt dann der Rest der Anwendung, bis die Anwendung schließlich beendet wird.&lt;/p>
&lt;p>In diesem Beitrag stellen wir einen Workaround vor, der für uns funktioniert hat.&lt;/p>
&lt;p>Zunächst galt es, den Ursprung für die Crashes zu ermitteln. Da die Anwendung neben dem WebEngine-Teil auch noch aus anderen, komplexeren Modulen besteht, fiel der Verdacht nicht gleich auf den WebEngine-Anteil. Viel wahrscheinlicher schien zunächst ein klassischer Memory Leak Bug zu sein. Also beispielsweise das neue Erstellen von C++ Objekten, ohne invalide oder nicht mehr benötigte Objekte hinterher zu entfernen und ggf. vorhandene Referenzen zu entfernen.&lt;/p>
&lt;p>Die Fehlermeldung im Qt Creator Log war:&lt;/p>
&lt;pre tabindex="0">&lt;code>[...] ERROR:broker_posix.cc(46) Received unexpected number of handles
[...] ERROR:platform_shared_memory_region_posix.cc(249) Creating shared memory in /dev/shm/.org.chromium.Chromium.Sf3dsf: Too many open files (24)
&lt;/code>&lt;/pre>&lt;p>Hier findet sich schon ein erstes Indiz, dass die Qt WebEngine etwas damit zu tun haben könnte. Dieser Teil unserer Anwendung scheint zu viele File Handles zu öffnen. Der Linux-Kernel verfügt über einen Kontrollmechanismus, der Anwendungen in der Zahl ihrer offenen File Handles beschränkt, sodass Ressourcenprobleme durch Amok-laufende Prozesse unwahrscheinlicher werden. Über das &lt;code>ulimit&lt;/code> Tool lassen sich die aktuell geltenden Einschränkungen einsehen (im Gültigkeitsbereich der Shell).&lt;/p>
&lt;p>Für einzelne Prozesse können die geltenden Limits mittels &lt;code>cat /proc/&amp;lt;PID&amp;gt;/limits&lt;/code> abgerufen werden. Über ein &lt;code>ls -1 /proc/&amp;lt;PID&amp;gt;/fd | wc -l&lt;/code> wird die Anzahl der offenen File Handles für einen Prozess zurückgegeben.&lt;/p>
&lt;p>Für unsere Anwendung lag die Zahl viel zu hoch. Langsam bei ca. 7.000 Handles beginnend entwickelte sich die Zahl der offenen Handles extrem schnell. Nach wenigen Minuten lag sie bereits im sechsstelligen Bereich.&lt;/p>
&lt;p>Je nach Benutzung der Webanwendung stieg die Zahl kaum oder sehr schnell. Vor allem bei intensiverer Benutzung des Web-Anteils der Anwendung stieg die Zahl rasant an. Da unsere WebApp eine beträchtliche Anzahl von Ajax-Requests im Hintergrund an einen REST API Server schickt, fiel der Verdacht zunächst auf offene Verbindungen seitens der Webanwendung. Hatte Chromium einen Bug und hielt Verbindungen aus irgendeinem Grund offen?&lt;/p>
&lt;p>Nach Deaktivierung der meisten Anfragen war schnell klar, dass die Hintergrundanfragen die Zahl der offenen File Handles nicht bedeutend beeinflusste. Alles andere wäre auch tatsächlich ein schwerer Bug in Chrome gewesen. Doch wieso beeinflusste die Benutzung der Webanwendung die Anzahl der offenen Handles dennoch so stark?&lt;/p>
&lt;p>Durch weiteres Experimentieren fanden wir heraus, dass unser Javascript-Code innerhalb der WebApp nichts mit dem Phänomen zu tun hatte. Stattdessen erhöhte sich die Anzahl der File Handles mit jeder visuellen Änderung innerhalb der WebEngine. Änderte sich eine Zahl oder wurde eine Animation aktiviert, schoss der Zähler in die Höhe. Änderte sich nichts auf der dargestellten Website, änderten sich auch die File Handles kaum.&lt;/p>
&lt;p>Hiermit waren wir mit unserem Code also raus. Der Bug lang im Verantwortungsbereich von Chromium, Qt oder Grafiktreiber-Code. Abschließend konnten wir die Ursache mangels Einsicht in die Funktionsweise der involvierten Komponenten nicht klären - Aber nach einigen weiteren Experimenten gelang es uns, unsere Anwendung so anzupassen, dass das Problem nicht mehr auftritt.&lt;/p>
&lt;p>Der Schlüssel war am Ende, in der Qt-Anwendung folgende Einstellung zu setzen:&lt;/p>
&lt;pre tabindex="0">&lt;code>QCoreApplication::setAttribute(Qt::AA_UseSoftwareOpenGL);
&lt;/code>&lt;/pre>&lt;p>Eigentlich bewirkt die &lt;a href="https://doc.qt.io/qt-6/qt.html#ApplicationAttribute-enum">Einstellung&lt;/a>, dass eine softwaregestützte, alternative OpenGL Implementierung genutzt wird. In den meisten Fällen wohl keine besonders attraktive Option. In unserem Fall bewahrt sie uns aber vor den Problemen, die wir mit der Standardeinstellung hatten und verursacht keine weiteren relevanten Nebeneffekte. Die Performance ist für unseren Anwendungsfall okay, sodass wir hiermit leben können.&lt;/p>
&lt;p>Als Ursache bleibt eine Inkompatibilität oder ein Bug zwischen unserem Raspberry Pi 4 Grafiktreiber und/oder Chromium bzw. der Qt WebEngine zu vermuten. Wie sich schon an anderer Stelle herausgestellt hat, kann der Raspberry Pi Grafikstack verwirrend und in bestimmten Konstellationen fehlerbehaftet sein. Das ist allerdings ein &amp;ldquo;Rabbit hole&amp;rdquo; für ein andermal &amp;hellip;&lt;/p></description></item><item><title>Qt 5.15.2 mit WebEngine (Chromium) bauen - RAM-Verbrauch begrenzen</title><link>https://blog.zero-iee.com/posts/qt-5.15.2-mit-webengine-ram-begrenzen/</link><pubDate>Wed, 11 Jan 2023 14:19:06 +0100</pubDate><guid>https://blog.zero-iee.com/posts/qt-5.15.2-mit-webengine-ram-begrenzen/</guid><description>&lt;p>Beim Kompilieren von Qt 5.15.2 aus den offiziellen Open Source Quellen sind wir in Kombination mit unserem Buildserver auf ein Problem getoßen: Der Buildprozess wurde beim Kompilieren der Chromium-basierten &amp;ldquo;WebEngine&amp;rdquo; Komponente mit zunächst mysteriösen Fehlermeldungen unterbrochen. Ein Blick in das Kernellog mittels &lt;code>dmesg -w&lt;/code> offenbarte dann schnell, dass der sog. OOM-Killer des Linux-Kernels zugeschlagen hatte. Offenbar war der RAM-Verbrauch des Buildprozesses so speicherintensiv, dass der Prozess abgebrochen werden musste, um das Betriebssystem lauffähig zu halten.&lt;/p>
&lt;p>Doch wie konnte das sein? Unser Buildserver verfügt über 32 GB RAM und 24 CPU-Kerne. Eine durchaus leistungsstarke Machine. Sie sollte eigentlich nicht so schnell an Leistungsgrenzen kommen.&lt;/p>
&lt;p>Das Problem wird durch zwei Faktoren verursacht. Zum einen ist das Bauen der Chromium Browser-Engine extrem speicherintensiv. Generell werden &lt;a href="https://chromium.googlesource.com/chromium/src/+/main/docs/linux/build_instructions.md">nicht weniger als 16 GB RAM empfohlen&lt;/a>. In unserem Fall kommt aber noch ein weiteres Problem hinzu: Per default erstellt &amp;ldquo;Ninja&amp;rdquo; - das in Chromium eingesetzte Buildsystem - für jeden verfügbaren virtuellen CPU Core einen Build-Thread, damit der Buildprozess maximal parallelisiert wird. Was für einen haushaltsüblichen PC mit 16 GB RAM noch gut funktionieren mag, zwingt unseren Buildserver mit seinen 24 Cores allerdings in die Knie. Jeder einzelne Thread braucht eine nicht zu unterschätzende Menge RAM. Am Ende stimmt bei unserem Server das Verhältnis aus CPU-Cores und verfügbarem RAM nicht mehr, sodass der Buildvorgang abbricht.&lt;/p>
&lt;p>Das Problem lässt sich verhindern, wenn wir die Anzahl der zu nutzenden Ninja-Threads künstlich verkleinern - wenn wir also nicht mit 24 CPU-Kernen bauen, sondern beispielsweise nur mit 18.&lt;/p>
&lt;p>Dazu kann vor einem &lt;code>make -j$(nproc)&lt;/code> die Umgebungsvariable &lt;code>NINJAJOBS&lt;/code> gesetzt werden. Anders, als man vielleicht vermuten würde &lt;em>(und anders, als es im &lt;a href="https://www.linuxfromscratch.org/blfs/view/svn/x/qtwebengine.html">LFS-Handbuch&lt;/a> beschrieben wird)&lt;/em>, wird hier allerdings nicht einfach nur eine Zahl hinterlegt, sondern der vollständige &lt;code>-j&lt;/code> &lt;a href="https://manpages.debian.org/testing/ninja-build/ninja.1.en.html">Parameter von Ninja&lt;/a>:&lt;/p>
&lt;pre>&lt;code>export NINJAJOBS=&amp;quot;-j16&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Wird darauf folgend ein &lt;code>make&lt;/code> ausgeführt, werden die üblichen Qt Komponenten mit allen Cores kompiliert, während die Ninja-basierten Anteile (in diesem Fall Chromium als Teil der WebEngine) mit weniger CPU Kernen gebaut werden, um den RAM zu schonen.&lt;/p>
&lt;p>Für unsere Kombination von 32 GB RAM und 24 CPU Cores haben wir experimentell eine Anzahl von 16 Kernel ermittelt, mit denen unser Buildprozess noch durchläuft. Mit nur 8 CPU-Kernen hatte die RAM-Auslastung bei ca 12 GB ihren Peak.&lt;/p></description></item></channel></rss>